{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach :\n",
    "\n",
    "1. Import vector embedding model\n",
    "2. Create three lexicons : \n",
    "    - Crisis\n",
    "        - High\n",
    "        - Medium\n",
    "        - Low\n",
    "        - Compute the TF-IDF for each category and use their average as score\n",
    "    - Temporal\n",
    "    - Severity\n",
    "3. Use argmax(threshold average similarity) -> crisis lexicon to classify embeddings \n",
    "4. Use tf-idf weighted average similarity -> temporal and severity lexicon to classify embeddings\n",
    "5. Final score  = (crisis_score + temporal_score * tf-idf + severity_score * tf-idf) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preprocessing:\n",
    "\n",
    "Clean the text data (remove irrelevant characters, handle URLs, etc.).\n",
    "2. Lexicon Creation:\n",
    "\n",
    "Crisis Keyword Lexicon: Keywords with base risk scores (e.g., \"kill myself\": 90, \"hopeless\": 60, \"sad\": 30). Categorize these (e.g., ideation, planning, attempt).\n",
    "Temporal Indicator Lexicon: Terms with weights (e.g., \"tonight\": +20, \"tomorrow\": +10, \"someday\": +2).\n",
    "Severity Modifier Lexicon: Modifiers with multipliers (e.g., \"extremely\": 1.8, \"slightly\": 0.7).\n",
    "3. Sample Phrase Processing (for Cluster Initialization):\n",
    "\n",
    "Create a sample set of phrases categorized as High, Medium, and Low risk. This is used only for initializing the clusters, not for direct comparison later.\n",
    "Generate embeddings for these sample phrases.\n",
    "Perform k-means clustering (k=3) on these embeddings.\n",
    "Calculate the centroid (average embedding) for each of the three clusters. These centroids represent your High, Medium, and Low risk categories in the embedding space.\n",
    "4. Inference Text Processing and Initial Risk Assignment (Embedding-Based):\n",
    "\n",
    "Generate an embedding for the inference text.\n",
    "Calculate the cosine similarity between the inference text embedding and each of the three cluster centroids (from Step 3).\n",
    "Assign the inference text to the category (High, Medium, Low) with the highest similarity.\n",
    "Assign an Initial Risk score based on this category:\n",
    "High: Initial Risk = 3\n",
    "Medium: Initial Risk = 2\n",
    "Low: Initial Risk = 1\n",
    "5. Lexicon-Based Scoring (Refinement and Transitions):\n",
    "\n",
    "5.1 Keyword Scoring:\n",
    "Find all crisis keywords in the inference text.\n",
    "For each keyword, calculate: Keyword Score = TF-IDF(keyword) * Base Risk(keyword).\n",
    "5.2 Severity Modification:\n",
    "Use dependency parsing to find severity modifiers linked to crisis keywords.\n",
    "For each modified keyword: Modified Keyword Score = Keyword Score * Modifier Multiplier.\n",
    "5.3 Temporal Adjustment:\n",
    "Find temporal indicators in the inference text.\n",
    "Temporal Score = Weight(temporal indicator).\n",
    "\n",
    "- **5.4 Sentiment Analysis**\n",
    "    - Use VADER to get sentiment score.\n",
    "5.5 Combined Lexicon Score:\n",
    "Lexicon Score = Sum(Modified Keyword Scores) + Temporal Score + Sentiment Score\n",
    "6. Final Risk Score (with Embedding-Informed Transitions):\n",
    "\n",
    "This is where we combine the embedding-based Initial Risk with the Lexicon Score. The key is to use the Lexicon Score to adjust the Initial Risk, allowing for transitions between risk levels.\n",
    "Threshold-Based Transitions:\n",
    "\n",
    "If Lexicon Score > Transition Threshold Up:\n",
    "  Final Risk = min(Initial Risk + 1, 3)  # Move up one level, max High\n",
    "Else If Lexicon Score < Transition Threshold Down:\n",
    "  Final Risk = max(Initial Risk - 1, 1)  # Move down one level, min Low\n",
    "Else:\n",
    "  Final Risk = Initial Risk  # Stay at the initial level\n",
    "Transition Threshold Up and Transition Threshold Down are values you'll need to tune (e.g., 25 and -15). These control how easily posts move between risk levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method: Sigmoid Mapping of Similarity Difference\n",
    "\n",
    "Prerequisites (Steps 1-3 remain the same):\n",
    "\n",
    "Clean text.\n",
    "\n",
    "Create lexicons (needed for later refinement, not this step).\n",
    "\n",
    "Create sample phrases (Low, Med, High).\n",
    "\n",
    "Generate embeddings for samples.\n",
    "\n",
    "K-means clustering (k=3) on sample embeddings.\n",
    "\n",
    "Calculate centroids: cent_low, cent_med, cent_high.\n",
    "\n",
    "Inference Text Embedding (Step 4a):\n",
    "\n",
    "Generate the embedding for the inference text: emb_inf.\n",
    "\n",
    "Calculate Similarities (Step 4b):\n",
    "\n",
    "Calculate cosine similarities:\n",
    "\n",
    "sim_low = cosine_similarity(emb_inf, cent_low)\n",
    "\n",
    "sim_med = cosine_similarity(emb_inf, cent_med) (We might not use this directly in the simplest sigmoid, but calculate it anyway)\n",
    "\n",
    "sim_high = cosine_similarity(emb_inf, cent_high)\n",
    "\n",
    "(Ensure similarities are in a reasonable range, typically [-1, 1] for cosine similarity, though often [0, 1] with common embedding models).\n",
    "\n",
    "Calculate Similarity Difference (New Step 4c):\n",
    "\n",
    "The core idea is to see how much more \"High\" the text is than \"Low\" based on embedding similarity.\n",
    "\n",
    "similarity_diff = sim_high - sim_low\n",
    "\n",
    "This value (similarity_diff) will be higher if the text is much closer to the High centroid than the Low, lower if closer to Low, and near zero if equidistant or if both similarities are low/high but similar. Its range is typically [-2, 2] or potentially narrower based on your embeddings/data.\n",
    "\n",
    "Apply Scaled Sigmoid Function (New Step 4d):\n",
    "\n",
    "Use the logistic function, scaled and shifted, to map similarity_diff to your desired score range (e.g., 1 to 3).\n",
    "\n",
    "The general form of a scaled logistic function is:\n",
    "Score = RangeMin + (RangeMax - RangeMin) / (1 + exp(-k * (input - midpoint)))\n",
    "\n",
    "Let's set:\n",
    "\n",
    "RangeMin = 1\n",
    "\n",
    "RangeMax = 3\n",
    "\n",
    "input = similarity_diff\n",
    "\n",
    "midpoint = 0 (We assume a difference of 0 should correspond to the middle score, i.e., 2).\n",
    "\n",
    "k = Steepness parameter (Controls how quickly the score transitions from 1 to 3. Higher k means a sharper transition around similarity_diff = 0. This needs tuning).\n",
    "\n",
    "Initial_Risk_Score = 1 + (3 - 1) / (1 + exp(-k * (similarity_diff - 0)))\n",
    "\n",
    "Initial_Risk_Score = 1 + 2 / (1 + exp(-k * (sim_high - sim_low)))\n",
    "\n",
    "Tuning Parameter k:\n",
    "\n",
    "Start with k=1 or k=2.\n",
    "\n",
    "Look at the similarity_diff values for your sample texts (or a validation set).\n",
    "\n",
    "If texts clearly belonging to High risk often have sim_high - sim_low around, say, 0.5, and Low risk texts have it around -0.5, you want k such that the function gives scores close to 3 for inputs >= 0.5 and close to 1 for inputs <= -0.5.\n",
    "\n",
    "If your similarity_diff values tend to be much smaller (e.g., +/- 0.1), you'll need a larger k (e.g., k=10 or k=20) to get sufficient separation.\n",
    "\n",
    "Plot the function 1 + 2 / (1 + exp(-k*x)) for different k values with x ranging across your typical similarity_diff values to visualize the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Serverity risk sentences\n",
    "high_risk = [\n",
    "    \"I don't want to live anymore\", \"I feel like ending it all\", \"No point in going on\",\n",
    "    \"I need to disappear\", \"I wish I never woke up\", \"It hurts too much to stay\",\n",
    "    \"I'm ready to give up\", \"I need a way to make it stop\", \"I keep thinking about ending things\",\n",
    "    \"I just want the pain to end\", \"Nobody would miss me if I were gone\", \n",
    "    \"I'm tired of pretending everything is okay\", \"I can't do this anymore\",\n",
    "    \"Everything is too much\", \"I feel trapped in my own mind\", \"I see no future for myself\",\n",
    "    \"No one understands what I'm going through\", \"I can't escape my thoughts\",\n",
    "    \"I don't deserve to live\", \"I just want to disappear forever\",\n",
    "    \"I wish I could sleep and never wake up\", \"I feel like I'm drowning and no one notices\",\n",
    "    \"I hate myself so much\", \"I can't stop thinking about how to end it\",\n",
    "    \"I've been planning my way out\", \"I hope this is the last time I feel this way\",\n",
    "    \"I feel like a burden to everyone\", \"Nothing makes sense anymore\",\n",
    "    \"Every day is unbearable\", \"The pain never stops\", \"I want to turn everything off\",\n",
    "    \"I just need a way out\", \"I'm done with everything\", \"I've lost all hope\",\n",
    "    \"No one would care if I was gone\", \"I feel completely empty inside\",\n",
    "    \"I have no energy left to fight\", \"I'm exhausted from pretending I'm okay\",\n",
    "    \"I wish I had the courage to do it\", \"I don't belong in this world\",\n",
    "    \"Why am I still here?\", \"I'm scared of myself\", \"I can't keep fighting these thoughts\",\n",
    "    \"I don't want to feel this anymore\", \"I feel like I'm suffocating\",\n",
    "    \"The voices in my head won't stop\", \"I'm tired of struggling\", \"I don't see the point anymore\",\n",
    "    \"I just need the pain to end\", \"I feel so hopeless\", \"This is my last goodbye\"\n",
    "]\n",
    "\n",
    "# medium_risk = [\n",
    "#     \"I feel lost lately\", \"I don't know who to talk to\", \"I'm struggling to cope\",\n",
    "#     \"Everything feels overwhelming\", \"I hate waking up every day\", \n",
    "#     \"I can't concentrate on anything anymore\", \"I just feel so numb\",\n",
    "#     \"I feel so alone even with people around\", \"I'm exhausted but I can't sleep\",\n",
    "#     \"Nothing makes me happy anymore\", \"I cry myself to sleep every night\",\n",
    "#     \"I feel like I'm drowning in my thoughts\", \"I don't want to burden anyone with my problems\",\n",
    "#     \"I drink to forget\", \"Smoking helps me escape my thoughts\", \n",
    "#     \"I don't even get high for fun anymore\", \"I need something stronger to cope\",\n",
    "#     \"I can't stop using, even though I want to\", \"I feel like I'm stuck in a loop\",\n",
    "#     \"I have no motivation for anything\", \"I'm just so tired all the time\",\n",
    "#     \"I keep overthinking every little thing\", \"I hate the way I feel every day\",\n",
    "#     \"Even simple tasks feel impossible\", \"I'm scared to open up to anyone\",\n",
    "#     \"I don't know how to explain what I'm feeling\", \"Everything feels so heavy\",\n",
    "#     \"I feel like I'm just existing, not living\", \"I hate how my mind never shuts up\",\n",
    "#     \"I can't tell if I'm sad or just empty\", \"Every day feels like the same nightmare\",\n",
    "#     \"I wish someone would check on me\", \"I don't know what I need, I just need help\",\n",
    "#     \"I feel like I'm constantly disappointing everyone\", \"I'm stuck in my own thoughts\",\n",
    "#     \"My mind is my worst enemy\", \"I've lost interest in everything I used to love\",\n",
    "#     \"I just want to feel normal again\", \"No matter what I do, I feel the same\",\n",
    "#     \"I keep pretending I'm okay but I'm not\", \"I can't stop the negative thoughts\",\n",
    "#     \"I feel like I'm losing myself\", \"I don't know what's wrong with me\",\n",
    "#     \"I wish I could just pause life for a while\", \"I miss being happy\",\n",
    "#     \"I wish someone understood me\", \"I feel so disconnected from reality\",\n",
    "#     \"I can't shake this feeling of emptiness\", \"I'm scared I'll feel like this forever\",\n",
    "#     \"I just want to be okay\"\n",
    "# ]\n",
    "\n",
    "low_risk = [\n",
    "    \"Mental health is important\", \"Therapy has helped me a lot\", \n",
    "    \"We need to talk about depression more\", \"Journaling has really helped my anxiety\",\n",
    "    \"It's okay to ask for help\", \"Taking a break for my mental health\",\n",
    "    \"Finding the right medication changed my life\", \"Self-care is so important\",\n",
    "    \"It's okay to not be okay\", \"Healing takes time\", \"Learning to set boundaries is hard\",\n",
    "    \"Exercise really helps my mood\", \"Meditation helps me stay grounded\",\n",
    "    \"Talking to friends makes a big difference\", \"Therapy isn't just for when you're struggling\",\n",
    "    \"Getting enough sleep is key to my mental health\",\n",
    "    \"Protecting my peace at all costs\", \"Gotta focus on my mental health today\",\n",
    "    \"Normalize taking mental health days\", \"I need to touch grass\",\n",
    "    \"Sending good vibes to everyone struggling\", \"Being mindful helps me stay present\",\n",
    "    \"A good routine helps my mental health\", \"Music is my therapy\",\n",
    "    \"I'm finally learning to love myself\", \"Having a support system is everything\",\n",
    "    \"Deep breathing really helps my anxiety\", \"Taking time for myself feels so good\",\n",
    "    \"Trying to stay positive every day\", \"Therapy has changed my perspective\",\n",
    "    \"I'm working on improving my mindset\", \"Setting boundaries has been life-changing\",\n",
    "    \"Talking about mental health should be normal\", \"Happiness is a journey, not a destination\",\n",
    "    \"Being kind to yourself is the first step\", \"Gratitude helps shift my perspective\",\n",
    "    \"Mental health days should be mandatory\", \"I'm finally prioritizing myself\",\n",
    "    \"Healing isn't linear, and that's okay\", \"Sleep is my best coping mechanism\",\n",
    "    \"Sometimes all you need is a deep breath\", \"I'm learning to forgive myself\",\n",
    "    \"Fresh air and a walk always help\", \"I try to focus on the little things\",\n",
    "    \"Checking in with yourself is important\", \"Mental health matters more than productivity\",\n",
    "    \"Journaling my thoughts helps me process emotions\", \"Being in nature helps clear my mind\",\n",
    "    \"Meditation is a game-changer\", \"Prioritizing my mental well-being every day\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the average embeddings for each of the three categories\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "load_dotenv(\"./.env\")\n",
    "def get_response(data):\n",
    "    api_key = os.getenv(\"JINA_API_KEY\")\n",
    "    URL = \"https://api.jina.ai/v1/embeddings\"\n",
    "\n",
    "    resp = requests.post(URL, headers={\"Authorization\": f\"Bearer {api_key}\"}, json={\"input\": data, \"model\" : \"jina-embeddings-v3\", \"task\" : \"classification\"})\n",
    "    return resp.json()[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_mean_pool(sentences):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        embeddings.append(get_response(sentence)[\"data\"][0][\"embedding\"])\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m high_risk_avg \u001b[38;5;241m=\u001b[39m calculate_mean_pool(high_risk)\n\u001b[1;32m      2\u001b[0m low_risk_avg \u001b[38;5;241m=\u001b[39m calculate_mean_pool(low_risk)\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mcalculate_mean_pool\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m      3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m----> 5\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(get_response(sentence)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "high_risk_avg = calculate_mean_pool(high_risk)\n",
    "low_risk_avg = calculate_mean_pool(low_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"high_risk_avg.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(high_risk_avg, f)\n",
    "\n",
    "# with open(\"medium_risk_avg.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(medium_risk_avg, f)\n",
    "\n",
    "# with open(\"low_risk_avg.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(low_risk_avg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk_avg = pickle.load(open(\"high_risk_avg.pkl\", \"rb\"))\n",
    "low_risk_avg = pickle.load(open(\"low_risk_avg.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_diff = high_risk_avg - low_risk_avg\n",
    "sim_diff = sim_diff / np.linalg.norm(sim_diff)\n",
    "\n",
    "# Save the sim_diff vector\n",
    "with open(\"sim_diff.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sim_diff, f)\n",
    "\n",
    "# Load the sim_diff vector\n",
    "sim_diff = pickle.load(open(\"sim_diff.pkl\", \"rb\"))\n",
    "\n",
    "def sigmoid_function(x, k = 4.5):\n",
    "    return 1+ (2 / (1 + np.exp(- k * x)))\n",
    "\n",
    "def cosine_similarity_with_sim_diff(text_embedding, sim_diff_vec = sim_diff):\n",
    "    return np.dot(text_embedding, sim_diff_vec) / (np.linalg.norm(text_embedding) * np.linalg.norm(sim_diff_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_basic_score (inference_text):\n",
    "    text_embedding = get_response(inference_text)\n",
    "    return sigmoid_function(cosine_similarity_with_sim_diff(text_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for neg statement : 1.3821438542628512\n"
     ]
    }
   ],
   "source": [
    "inference_text = \"Prioritizing my mental well-being every day\"\n",
    "# inf_2 = \"when all else is lost, the hope still remains. It is mankind's greatest gift\"\n",
    "# inf_2 = \"I'm working on improving my mindset\"\n",
    "\n",
    "print(f\"Score for neg statement : {inference_basic_score(inference_text)}\")\n",
    "# print(f\"Score for pos statement : {inference_basic_score(inf_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
